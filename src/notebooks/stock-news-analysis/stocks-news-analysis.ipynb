{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: newspaper3k in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (0.2.8)\r\n",
      "Requirement already satisfied: Pillow>=3.3.0 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from newspaper3k) (8.4.0)\r\n",
      "Requirement already satisfied: lxml>=3.6.0 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from newspaper3k) (4.7.1)\r\n",
      "Requirement already satisfied: tldextract>=2.0.1 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from newspaper3k) (3.1.2)\r\n",
      "Requirement already satisfied: feedparser>=5.2.1 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from newspaper3k) (6.0.8)\r\n",
      "Requirement already satisfied: jieba3k>=0.35.1 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from newspaper3k) (0.35.1)\r\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from newspaper3k) (4.10.0)\r\n",
      "Requirement already satisfied: requests>=2.10.0 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from newspaper3k) (2.27.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from newspaper3k) (2.8.2)\r\n",
      "Requirement already satisfied: nltk>=3.2.1 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from newspaper3k) (3.6.7)\r\n",
      "Requirement already satisfied: tinysegmenter==0.3 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from newspaper3k) (0.3)\r\n",
      "Requirement already satisfied: feedfinder2>=0.0.4 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from newspaper3k) (0.0.4)\r\n",
      "Requirement already satisfied: PyYAML>=3.11 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from newspaper3k) (5.3.1)\r\n",
      "Requirement already satisfied: cssselect>=0.9.2 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from newspaper3k) (1.1.0)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.3.1)\r\n",
      "Requirement already satisfied: six in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from feedfinder2>=0.0.4->newspaper3k) (1.14.0)\r\n",
      "Requirement already satisfied: sgmllib3k in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.2.1->newspaper3k) (2022.1.18)\r\n",
      "Requirement already satisfied: click in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.2.1->newspaper3k) (7.0)\r\n",
      "Requirement already satisfied: tqdm in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.2.1->newspaper3k) (4.62.3)\r\n",
      "Requirement already satisfied: joblib in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.2.1->newspaper3k) (1.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.10.0->newspaper3k) (3.3)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.10.0->newspaper3k) (2.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.10.0->newspaper3k) (2021.10.8)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.10.0->newspaper3k) (1.26.7)\r\n",
      "Requirement already satisfied: requests-file>=1.4 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\r\n",
      "Requirement already satisfied: filelock>=3.0.8 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from tldextract>=2.0.1->newspaper3k) (3.4.0)\r\n",
      "Requirement already satisfied: GoogleNews in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (1.6.0)\r\n",
      "Requirement already satisfied: python-dateutil in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from GoogleNews) (2.8.2)\r\n",
      "Requirement already satisfied: dateparser in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from GoogleNews) (1.1.0)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from GoogleNews) (4.10.0)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4->GoogleNews) (2.3.1)\r\n",
      "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from dateparser->GoogleNews) (2022.1.18)\r\n",
      "Requirement already satisfied: tzlocal in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from dateparser->GoogleNews) (4.1)\r\n",
      "Requirement already satisfied: pytz in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from dateparser->GoogleNews) (2021.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil->GoogleNews) (1.14.0)\r\n",
      "Requirement already satisfied: pytz-deprecation-shim in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from tzlocal->dateparser->GoogleNews) (0.1.0.post0)\r\n",
      "Requirement already satisfied: tzdata in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from pytz-deprecation-shim->tzlocal->dateparser->GoogleNews) (2021.5)\r\n",
      "Requirement already satisfied: nltk in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (3.6.7)\r\n",
      "Requirement already satisfied: joblib in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.1.0)\r\n",
      "Requirement already satisfied: tqdm in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from nltk) (4.62.3)\r\n",
      "Requirement already satisfied: click in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from nltk) (7.0)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from nltk) (2022.1.18)\r\n",
      "Requirement already satisfied: wordcloud in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (1.8.1)\r\n",
      "Requirement already satisfied: pillow in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from wordcloud) (8.4.0)\r\n",
      "Requirement already satisfied: matplotlib in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from wordcloud) (3.4.3)\r\n",
      "Requirement already satisfied: numpy>=1.6.1 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from wordcloud) (1.21.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (0.11.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (1.3.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (2.8.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->wordcloud) (3.0.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/arungupta/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.14.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install newspaper3k\n",
    "!pip install GoogleNews\n",
    "!pip install nltk\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/arungupta/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from GoogleNews import GoogleNews\n",
    "from newspaper import Article\n",
    "from newspaper import Config\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/arungupta/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "now = dt.date.today()\n",
    "now = now.strftime('%m-%d-%Y')\n",
    "yesterday = dt.date.today() - dt.timedelta(days = 5)\n",
    "yesterday = yesterday.strftime('%m-%d-%Y')\n",
    "\n",
    "nltk.download('punkt')\n",
    "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:78.0) Gecko/20100101 Firefox/78.0'\n",
    "config = Config()\n",
    "config.browser_user_agent = user_agent\n",
    "config.request_timeout = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for and analyzing ACC.NS, Please be patient, it might take a while...\n",
      "'NoneType' object is not iterable\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['media', 'title'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/xm/04s2ld0n1jqbwfgytc7tjrf00000gn/T/ipykernel_75702/1792387982.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0;31m#store the results\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'media'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'title'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3462\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mis_iterator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3463\u001B[0m                 \u001B[0mkey\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3464\u001B[0;31m             \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_listlike_indexer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3465\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3466\u001B[0m         \u001B[0;31m# take() does not accept boolean indexers\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001B[0m in \u001B[0;36m_get_listlike_indexer\u001B[0;34m(self, key, axis)\u001B[0m\n\u001B[1;32m   1312\u001B[0m             \u001B[0mkeyarr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindexer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnew_indexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0max\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reindex_non_unique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeyarr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1313\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1314\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_validate_read_indexer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeyarr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindexer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1315\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1316\u001B[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001B[0m in \u001B[0;36m_validate_read_indexer\u001B[0;34m(self, key, indexer, axis)\u001B[0m\n\u001B[1;32m   1372\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0muse_interval_msg\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1373\u001B[0m                     \u001B[0mkey\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1374\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1375\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1376\u001B[0m             \u001B[0mnot_found\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mensure_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mmissing_mask\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnonzero\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: \"None of [Index(['media', 'title'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "selected_stock = 'ACC.NS'\n",
    "if selected_stock != '':\n",
    "    print(f'Searching for and analyzing {selected_stock}, Please be patient, it might take a while...')\n",
    "\n",
    "    #Extract News with Google News\n",
    "    googlenews = GoogleNews(start=yesterday,end=now)\n",
    "    googlenews.search(selected_stock)\n",
    "    result = googlenews.result()\n",
    "    #store the results\n",
    "    df = pd.DataFrame(result)\n",
    "    print(df[['media','title']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    list =[] #creating an empty list\n",
    "    for i in df.index:\n",
    "        dict = {} #creating an empty dictionary to append an article in every single iteration\n",
    "        article = Article(df['link'][i],config=config) #providing the link\n",
    "        try:\n",
    "            article.download() #downloading the article\n",
    "            article.parse() #parsing the article\n",
    "            article.nlp() #performing natural language processing (nlp)\n",
    "        except:\n",
    "            pass\n",
    "            #storing results in our empty dictionary\n",
    "        dict['Date']=df['date'][i]\n",
    "        dict['Media']=df['media'][i]\n",
    "        dict['Title']=article.title\n",
    "        dict['Article']=article.text\n",
    "        dict['Summary']=article.summary\n",
    "        dict['Key_words']=article.keywords\n",
    "        list.append(dict)\n",
    "    check_empty = not any(list)\n",
    "    # print(check_empty)\n",
    "    if check_empty == False:\n",
    "        news_df=pd.DataFrame(list) #creating dataframe\n",
    "        print(news_df)\n",
    "\n",
    "except Exception as e:\n",
    "    #exception handling\n",
    "    print(\"exception occurred:\" + str(e))\n",
    "    print('Looks like, there is some error in retrieving the data, Please try again or try with a different ticker.' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'news_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/xm/04s2ld0n1jqbwfgytc7tjrf00000gn/T/ipykernel_75702/2868260719.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;31m#Iterating over the tweets in the dataframe\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 16\u001B[0;31m \u001B[0;32mfor\u001B[0m \u001B[0mnews\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mnews_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'Summary'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     17\u001B[0m     \u001B[0mnews_list\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnews\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[0manalyzer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSentimentIntensityAnalyzer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpolarity_scores\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnews\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'news_df' is not defined"
     ]
    }
   ],
   "source": [
    "#Sentiment Analysis\n",
    "def percentage(part,whole):\n",
    "    return 100 * float(part)/float(whole)\n",
    "\n",
    "#Assigning Initial Values\n",
    "positive = 0\n",
    "negative = 0\n",
    "neutral = 0\n",
    "#Creating empty lists\n",
    "news_list = []\n",
    "neutral_list = []\n",
    "negative_list = []\n",
    "positive_list = []\n",
    "\n",
    "#Iterating over the tweets in the dataframe\n",
    "for news in news_df['Summary']:\n",
    "    news_list.append(news)\n",
    "    analyzer = SentimentIntensityAnalyzer().polarity_scores(news)\n",
    "    neg = analyzer['neg']\n",
    "    neu = analyzer['neu']\n",
    "    pos = analyzer['pos']\n",
    "    comp = analyzer['compound']\n",
    "\n",
    "    if neg > pos:\n",
    "        negative_list.append(news) #appending the news that satisfies this condition\n",
    "        negative += 1 #increasing the count by 1\n",
    "    elif pos > neg:\n",
    "        positive_list.append(news) #appending the news that satisfies this condition\n",
    "        positive += 1 #increasing the count by 1\n",
    "    elif pos == neg:\n",
    "        neutral_list.append(news) #appending the news that satisfies this condition\n",
    "        neutral += 1 #increasing the count by 1\n",
    "\n",
    "positive = percentage(positive, len(news_df)) #percentage is the function defined above\n",
    "negative = percentage(negative, len(news_df))\n",
    "neutral = percentage(neutral, len(news_df))\n",
    "\n",
    "#Converting lists to pandas dataframe\n",
    "news_list = pd.DataFrame(news_list)\n",
    "neutral_list = pd.DataFrame(neutral_list)\n",
    "negative_list = pd.DataFrame(negative_list)\n",
    "positive_list = pd.DataFrame(positive_list)\n",
    "#using len(length) function for counting\n",
    "print(\"Positive Sentiment:\", '%.2f' % len(positive_list), end='\\n')\n",
    "print(\"Neutral Sentiment:\", '%.2f' % len(neutral_list), end='\\n')\n",
    "print(\"Negative Sentiment:\", '%.2f' % len(negative_list), end='\\n')\n",
    "\n",
    "#Creating PieCart\n",
    "labels = ['Positive ['+str(round(positive))+'%]' , 'Neutral ['+str(round(neutral))+'%]','Negative ['+str(round(negative))+'%]']\n",
    "sizes = [positive, neutral, negative]\n",
    "colors = ['yellowgreen', 'blue','red']\n",
    "patches, texts = plt.pie(sizes,colors=colors, startangle=90)\n",
    "plt.style.use('default')\n",
    "plt.legend(labels)\n",
    "plt.title(\"Sentiment Analysis Result for stock= \"+selected_stock+\"\" )\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "# Word cloud visualization\n",
    "def word_cloud(text):\n",
    "    stopwords = set(STOPWORDS)\n",
    "    allWords = ' '.join([nws for nws in text])\n",
    "    wordCloud = WordCloud(background_color='black',width = 1600, height = 800,stopwords = stopwords,min_font_size = 20,max_font_size=150,colormap='prism').generate(allWords)\n",
    "    fig, ax = plt.subplots(figsize=(20,10), facecolor='k')\n",
    "    plt.imshow(wordCloud)\n",
    "    ax.axis(\"off\")\n",
    "    fig.tight_layout(pad=0)\n",
    "    plt.show()\n",
    "\n",
    "print('Wordcloud for ' + selected_stock)\n",
    "word_cloud(news_df['Summary'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}